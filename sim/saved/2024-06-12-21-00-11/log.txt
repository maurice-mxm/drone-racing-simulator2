Logging to /home/maurice/workspace/drone-racing-simulator/sim/saved/2024-06-12-21-00-11
--------------------------------------
| approxkl           | 0.745672      |
| clipfrac           | 0.64273596    |
| ep_len_mean        | 0             |
| ep_reward_mean     | 0             |
| explained_variance | -3.32e+03     |
| fps                | 7560          |
| n_updates          | 1             |
| policy_entropy     | 5.6769037     |
| policy_loss        | 0.14136897    |
| serial_timesteps   | 250           |
| time_elapsed       | 0.00125       |
| total_timesteps    | 25000         |
| true_reward        | -0.0041783536 |
| value_loss         | 45.50302      |
--------------------------------------
--------------------------------------
| approxkl           | 0.20378077    |
| clipfrac           | 0.60396       |
| ep_len_mean        | 0             |
| ep_reward_mean     | 0             |
| explained_variance | -3.67e+04     |
| fps                | 45898         |
| n_updates          | 2             |
| policy_entropy     | 5.6819797     |
| policy_loss        | 0.11653701    |
| serial_timesteps   | 500           |
| time_elapsed       | 4.89          |
| total_timesteps    | 50000         |
| true_reward        | -0.0042889165 |
| value_loss         | 3.1180108     |
--------------------------------------
-------------------------------------
| approxkl           | 0.11261765   |
| clipfrac           | 0.526024     |
| ep_len_mean        | 0            |
| ep_reward_mean     | 0            |
| explained_variance | -1.72e+03    |
| fps                | 44559        |
| n_updates          | 3            |
| policy_entropy     | 5.6848187    |
| policy_loss        | 0.075566724  |
| serial_timesteps   | 750          |
| time_elapsed       | 7.16         |
| total_timesteps    | 75000        |
| true_reward        | -0.004183158 |
| value_loss         | 0.51097095   |
-------------------------------------
-------------------------------------
| approxkl           | 0.020823425  |
| clipfrac           | 0.242148     |
| ep_len_mean        | 0            |
| ep_reward_mean     | 0            |
| explained_variance | -2.37e+03    |
| fps                | 45112        |
| n_updates          | 4            |
| policy_entropy     | 5.6863184    |
| policy_loss        | 0.012450835  |
| serial_timesteps   | 1000         |
| time_elapsed       | 9.21         |
| total_timesteps    | 100000       |
| true_reward        | -0.004228594 |
| value_loss         | 0.15400992   |
-------------------------------------
--------------------------------------
| approxkl           | 0.015104933   |
| clipfrac           | 0.153424      |
| ep_len_mean        | 0             |
| ep_reward_mean     | 0             |
| explained_variance | -306          |
| fps                | 46436         |
| n_updates          | 5             |
| policy_entropy     | 5.688972      |
| policy_loss        | 0.0036002155  |
| serial_timesteps   | 1250          |
| time_elapsed       | 11.3          |
| total_timesteps    | 125000        |
| true_reward        | -0.0042384393 |
| value_loss         | 0.028677097   |
--------------------------------------
-------------------------------------
| approxkl           | 0.015894052  |
| clipfrac           | 0.20233998   |
| ep_len_mean        | 0            |
| ep_reward_mean     | 0            |
| explained_variance | -48.9        |
| fps                | 41252        |
| n_updates          | 6            |
| policy_entropy     | 5.6898293    |
| policy_loss        | 0.0057724016 |
| serial_timesteps   | 1500         |
| time_elapsed       | 13.3         |
| total_timesteps    | 150000       |
| true_reward        | -0.004172836 |
| value_loss         | 0.0098091755 |
-------------------------------------
-------------------------------------
| approxkl           | 0.031387366  |
| clipfrac           | 0.24893601   |
| ep_len_mean        | 0            |
| ep_reward_mean     | 0            |
| explained_variance | -18.9        |
| fps                | 46081        |
| n_updates          | 7            |
| policy_entropy     | 5.68927      |
| policy_loss        | 0.0034243655 |
| serial_timesteps   | 1750         |
| time_elapsed       | 15.4         |
| total_timesteps    | 175000       |
| true_reward        | -0.004177247 |
| value_loss         | 0.0041033505 |
-------------------------------------
--------------------------------------
| approxkl           | 0.065770015   |
| clipfrac           | 0.4722        |
| ep_len_mean        | 0             |
| ep_reward_mean     | 0             |
| explained_variance | -3.19         |
| fps                | 40223         |
| n_updates          | 8             |
| policy_entropy     | 5.688235      |
| policy_loss        | 0.026963692   |
| serial_timesteps   | 2000          |
| time_elapsed       | 17.4          |
| total_timesteps    | 200000        |
| true_reward        | -0.0041065635 |
| value_loss         | 0.027248392   |
--------------------------------------
-------------------------------------
| approxkl           | 0.013962018  |
| clipfrac           | 0.188832     |
| ep_len_mean        | 0            |
| ep_reward_mean     | 0            |
| explained_variance | -9.89        |
| fps                | 41642        |
| n_updates          | 9            |
| policy_entropy     | 5.6872387    |
| policy_loss        | 0.0031317286 |
| serial_timesteps   | 2250         |
| time_elapsed       | 19.5         |
| total_timesteps    | 225000       |
| true_reward        | -0.00414159  |
| value_loss         | 0.012966233  |
-------------------------------------
--------------------------------------
| approxkl           | 0.013185583   |
| clipfrac           | 0.157884      |
| ep_len_mean        | 0             |
| ep_reward_mean     | 0             |
| explained_variance | -18.8         |
| fps                | 47005         |
| n_updates          | 10            |
| policy_entropy     | 5.686909      |
| policy_loss        | 0.005308093   |
| serial_timesteps   | 2500          |
| time_elapsed       | 21.5          |
| total_timesteps    | 250000        |
| true_reward        | -0.0042052697 |
| value_loss         | 0.016159862   |
--------------------------------------
-------------------------------------
| approxkl           | 0.014758791  |
| clipfrac           | 0.18417999   |
| ep_len_mean        | 0            |
| ep_reward_mean     | 0            |
| explained_variance | -13.8        |
| fps                | 47200        |
| n_updates          | 11           |
| policy_entropy     | 5.6837854    |
| policy_loss        | 0.004534711  |
| serial_timesteps   | 2750         |
| time_elapsed       | 23.5         |
| total_timesteps    | 275000       |
| true_reward        | -0.004267175 |
| value_loss         | 0.011227718  |
-------------------------------------
--------------------------------------
| approxkl           | 0.025841027   |
| clipfrac           | 0.27233598    |
| ep_len_mean        | 0             |
| ep_reward_mean     | 0             |
| explained_variance | -8.17         |
| fps                | 46691         |
| n_updates          | 12            |
| policy_entropy     | 5.6813383     |
| policy_loss        | 0.0025564858  |
| serial_timesteps   | 3000          |
| time_elapsed       | 25.5          |
| total_timesteps    | 300000        |
| true_reward        | -0.0041577895 |
| value_loss         | 0.007045499   |
--------------------------------------
-------------------------------------
| approxkl           | 0.012059924  |
| clipfrac           | 0.156908     |
| ep_len_mean        | 0            |
| ep_reward_mean     | 0            |
| explained_variance | -1.58        |
| fps                | 45319        |
| n_updates          | 13           |
| policy_entropy     | 5.679818     |
| policy_loss        | 0.00193657   |
| serial_timesteps   | 3250         |
| time_elapsed       | 27.5         |
| total_timesteps    | 325000       |
| true_reward        | -0.003981141 |
| value_loss         | 0.011161807  |
-------------------------------------
--------------------------------------
| approxkl           | 0.038918324   |
| clipfrac           | 0.19356401    |
| ep_len_mean        | 0             |
| ep_reward_mean     | 0             |
| explained_variance | 0.364         |
| fps                | 42539         |
| n_updates          | 14            |
| policy_entropy     | 5.678117      |
| policy_loss        | 0.017542336   |
| serial_timesteps   | 3500          |
| time_elapsed       | 29.5          |
| total_timesteps    | 350000        |
| true_reward        | -0.0034599002 |
| value_loss         | 0.025597671   |
--------------------------------------
--------------------------------------
| approxkl           | 0.09538491    |
| clipfrac           | 0.16569999    |
| ep_len_mean        | 0             |
| ep_reward_mean     | 0             |
| explained_variance | 0.303         |
| fps                | 45927         |
| n_updates          | 15            |
| policy_entropy     | 5.6784453     |
| policy_loss        | 0.02601344    |
| serial_timesteps   | 3750          |
| time_elapsed       | 31.6          |
| total_timesteps    | 375000        |
| true_reward        | -0.0033029309 |
| value_loss         | 0.025173372   |
--------------------------------------
--------------------------------------
| approxkl           | 0.23992352    |
| clipfrac           | 0.09878801    |
| ep_len_mean        | 0             |
| ep_reward_mean     | 0             |
| explained_variance | -0.284        |
| fps                | 46138         |
| n_updates          | 16            |
| policy_entropy     | 5.6804724     |
| policy_loss        | 0.019950006   |
| serial_timesteps   | 4000          |
| time_elapsed       | 33.6          |
| total_timesteps    | 400000        |
| true_reward        | -0.0037256773 |
| value_loss         | 0.01609667    |
--------------------------------------
--------------------------------------
| approxkl           | 0.014118418   |
| clipfrac           | 0.18004401    |
| ep_len_mean        | 0             |
| ep_reward_mean     | 0             |
| explained_variance | 0.176         |
| fps                | 38048         |
| n_updates          | 17            |
| policy_entropy     | 5.680872      |
| policy_loss        | 0.00626533    |
| serial_timesteps   | 4250          |
| time_elapsed       | 35.7          |
| total_timesteps    | 425000        |
| true_reward        | -0.0026661358 |
| value_loss         | 0.023413418   |
--------------------------------------
--------------------------------------
| approxkl           | 0.023629768   |
| clipfrac           | 0.189456      |
| ep_len_mean        | 0             |
| ep_reward_mean     | 0             |
| explained_variance | 0.479         |
| fps                | 43771         |
| n_updates          | 18            |
| policy_entropy     | 5.680932      |
| policy_loss        | 0.017294561   |
| serial_timesteps   | 4500          |
| time_elapsed       | 37.8          |
| total_timesteps    | 450000        |
| true_reward        | -0.0027272815 |
| value_loss         | 0.020049874   |
--------------------------------------
